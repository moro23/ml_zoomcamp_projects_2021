{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa70740",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "We are going to solve an image classifiction problem, by predicting whether an image is a T-shit, a shirt, a dress, or something else. \n",
    "By doing so, we would be training a deep neural network using TensorFlow and Keras to recognize the types of clothes. <br>\n",
    "\n",
    "The plan for our project is\n",
    "- First, we download the dataset and use a pretrained model to classify images.\n",
    "- Then, we talk about neural networks, and see how they work internally.\n",
    "- After that, we adjust the pretrained neural network for solving our tasks.\n",
    "- Finally, we expand our dataset by generating many more images from the images\n",
    "we have.\n",
    "\n",
    "For evaluating the quality of our models, let’s use accuracy: the percentage of items we\n",
    "classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download the clothing dataset\n",
    "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets import our libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import kerasas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf45ea2",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the library\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the images \n",
    "load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0eb209",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "A convolutional neural network extracts visual patterns from an image and use them for classification. \n",
    "\n",
    "### Using a pretrained model \n",
    "Pretrained models are a type of network architecture that has already been trained on a particular type of dataset(ImageNet) and can be used for general-purpose image classification.  \n",
    "\n",
    "Loading our model \n",
    "We specify two parameters here:\n",
    " weights: We want to use a pretrained model from ImageNet.\n",
    " imput_shape: The size of the input images: height, width, and the number of\n",
    "channels. We resize the images to 299 × 299, and each image has three channels: red, green and blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a41df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets import our pretrained model and other helpful functions \n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84570d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab64e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets load the images from disk in small batches\n",
    "train_gen = ImageDataGenerator(\n",
    "    ##lets apply the preprocess_input function to each image\n",
    "    preprocessing_function=preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets point the train_gen to the directory with the data\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    ##loads all the images from the train dir\n",
    "    \"clothing-dataset-small/train/\",\n",
    "    \n",
    "    ##lets resize the images \n",
    "    target_size=(150, 150),\n",
    "    \n",
    "    ##lets load the images in batches\n",
    "    batch_size=32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1bb0a",
   "metadata": {},
   "source": [
    "Lets repeart same for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b011379",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = ImageDataGenerator(\n",
    "    \n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "valid_ds = valid_gen.flow_from_directory(\n",
    "\n",
    "    \"clothing-dataset-small/validation/\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83a4b6",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "We begin by loading the base model which is the pretrained model that we're using for extracting the vector representation from the images by including the part with pretrained convolutional layers. \n",
    "Next we add our own dense layers. <br>\n",
    "By seeting the include_top parameter to False, we explicitly specify that we're not interested in the dense layers of the pretrained neural network, only in the convolutional layers. <br>\n",
    "We avoid training the base mode by setting the trainable parameter to False. This freezes the base model and attempting to train the base_model would destroy all the filter. <br>\n",
    "\n",
    "Building the base model: \n",
    "we would use functional styling to build the model\n",
    "- creating the base model\n",
    "- we use the base model as a function by giving it two parameters: inputs, and training=False\n",
    "- we create a pooling layer: which is a special construction that allows us to convert the output of a convolutional layer into a vector and immediately invoke it with base as the argument. meaning the input to this layer comes from base. \n",
    "- we create a dense layer and connect it with vector. \n",
    "- we wrap the inputs and outputs into a Model class by specifying two things\n",
    "what the model will get as input,\n",
    "what the output of the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e260e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create the base model\n",
    "base_model = Xception(\n",
    "    \n",
    "    ##lets use the pretrained model on ImageNet\n",
    "    weights='imagenet',\n",
    "    \n",
    "    ##keep only the convolutional layers\n",
    "    include_top=False,\n",
    "    \n",
    "    ## images should be 150 x 150 with three channels\n",
    "    input_shape=(150, 150, 3),\n",
    "\n",
    ")\n",
    "\n",
    "## lets freeze the base model \n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets specify the input and the size of the array\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "## create the base model \n",
    "## lets extract high-level features \n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "##lets extract the vector representation by converting the output of the base_model to a vector\n",
    "vector = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "##adds a dense layer of size 10: one element for each class\n",
    "outputs = keras.layers.Dense(10)(vector)\n",
    "\n",
    "## combines the inputs and the outputs into a keras model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd71df",
   "metadata": {},
   "source": [
    "### Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##setting the learning rate\n",
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38914f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c07148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa709b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27f649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f12c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275aa577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a3207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a5f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd040980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e74b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22022956",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
