{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a0f7fb",
   "metadata": {},
   "source": [
    "## Problem Statement \n",
    "Before agreeing to give a loan, we want to score the\n",
    "customer and assess their chances of default. If it’s too high, we reject the application.\n",
    "This process is called “credit risk scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94ba51",
   "metadata": {},
   "source": [
    "## Download dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9554e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/gastonstat/CreditScoring/raw/master/CreditScoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586c214",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ed9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ab68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data into our project\n",
    "df = pd.read_csv(\"CreditScoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets see an overview of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets normalize all the column names to lowercase letters\n",
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca68e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8555bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets change in values in the status columsn \n",
    "## by mapping them unto new values \n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    3: 'unk'\n",
    "}\n",
    "\n",
    "## lets use the dictionary to do the mapping\n",
    "df.status = df.status.map(status_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_values = {\n",
    "    \n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "    \n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98cdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_values = {\n",
    "    \n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_values = {\n",
    "    \n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'parttime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d415fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c194dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets view statistical summary of the dataset\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f338a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets replace artificial values in our dataset\n",
    "\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e95d1",
   "metadata": {},
   "source": [
    "## Target Variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75721cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39f851",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "- Split the dataset into train, validation, and test. (60%, 20%, 20%)\n",
    "- Handle missing values.\n",
    "- Use one-hot encoding to encode categorical variables.\n",
    "- Create the feature matrix X and the target variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bfbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libaries\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ed1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce965bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df_train_full, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4301bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train set {len(df_train)}')\n",
    "print(f'Valid set {len(df_valid)}')\n",
    "print(f'Test set {len(df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043cb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets select our target variables\n",
    "y_train = (df_train.status == 'default').values\n",
    "y_valid = (df_valid.status == 'default').values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets delete the selected target columns from the dataframe\n",
    "del df_train['status']\n",
    "del df_valid['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85498fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check for missing values in our dataset\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_valid.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98486d8",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "- lets encode our categorical variables in the our dataframe\n",
    "- Implement our DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9820533",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert our dataframe into a list of dictionaries\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "valid_dict = df_valid.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_valid = dv.fit_transform(valid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61203cc3",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "A decision tree is a data structure that encodes a series of if-then-else rules. <br>\n",
    "Each node in a tree contains a condition. If the condition is satisfied, we go to the <br>\n",
    "right side of the tree; otherwise, we go to the left. In the end we arrive at the final decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd05545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets implements a decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cl_model = DecisionTreeClassifier()\n",
    "dt_cl_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778372c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets make \n",
    "y_train_pred = dt_cl_model.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16705aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed71b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets evaluate our model using the AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check the accuracy on our validation dataset\n",
    "y_valid_pred = dt_cl_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets evaluate our model using the AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "valid_auc_score = roc_auc_score(y_valid, y_valid_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {valid_auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73c82e",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5428ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets implements a decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_cl_model = DecisionTreeClassifier(max_depth=2)\n",
    "dt_cl_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34384ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets make \n",
    "y_train_pred = dt_cl_model.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets evaluate our model using the AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_auc_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check the accuracy on our validation dataset\n",
    "y_valid_pred = dt_cl_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets evaluate our model using the AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "valid_auc_score = roc_auc_score(y_valid, y_valid_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {valid_auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ad8bd",
   "metadata": {},
   "source": [
    "#### IMPURITY\n",
    "When training a decision tree model, we want to find such T that the impurity of both groups is minimal.<br>\n",
    "So, the algorithm for finding T is quite simple:\n",
    "- Try all possible values of T.\n",
    "- For each T, split the dataset into left and right groups and measure their impurity.\n",
    "- Select T that has the lowest degree of impurity.\n",
    "\n",
    "#### STOPPING CRITERIA \n",
    "To decide if we want to continue splitting the data, we use stopping criteria <br>\n",
    "criteria that describe if we should add another split in the tree or stop. <br>\n",
    "The most common stopping criteria are\n",
    "- The group is already pure.\n",
    "- The tree reached the depth limit (controlled by the max_depth parameter).\n",
    "- The group is too small to continue splitting (controlled by the min_samples_leaf parameter).\n",
    "\n",
    "Let’s use this information to adjust the training algorithm:\n",
    "- Find the best split:\n",
    "    - For each feature try all possible threshold values.\n",
    "    - Use the one with the lowest impurity.\n",
    "- If the maximum allowed depth is reached, stop.\n",
    "- If the group on the left is sufficiently large and it’s not pure yet, repeat on the left.\n",
    "- If the group on the right is sufficiently large and it’s not pure yet, repeat on the right.\n",
    "\n",
    "### Parameter tuning for decision tree \n",
    "Parameter tuning involves finding the best parameters of the model. <br>\n",
    "This usually consist of chaning the model and checking its score on the validation dataset.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets tune the max_depth parameter with a few reasonable value\n",
    "for depth in [1, 2, 3, 4, 5, 6, 10, 15, 20, None]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred_valid = dt.predict_proba(X_valid)[:, 1]\n",
    "    valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    print(f\"{depth} -> {round(valid_auc_score, 3)}\")\n",
    "    #print(f\"{depth} -> {valid_auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3edf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's tune the min_leaf_size parameter \n",
    "for depth in [3, 4, 5, 6]:\n",
    "    for leaf in [1, 5, 10, 15, 20, 100, 200]:\n",
    "        dt = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=leaf)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred_valid = dt.predict_proba(X_valid)[:, 1]\n",
    "        valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "        print(f\"{depth} -> {leaf} -> {round(valid_auc_score, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets train our final model\n",
    "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=20)\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7fa4c",
   "metadata": {},
   "source": [
    "## Random forest \n",
    "The combination of mutiple models for predictive purposes is known as ensemble learning,<br>\n",
    "and a combination of models is called an ensemble. The easiest way to have different models is to train each tree on a different subset of features. <br> \n",
    "This way of putting together multiple decision trees into an ensemble is called a random forest.<br>\n",
    "To train a random forest, we can do this (figure 6.26):\n",
    "- Train N independent decision tree models.\n",
    "- For each model, select a random subset of features, and use only them fortraining.\n",
    "- When predicting, combine the output of N models into one.\n",
    "\n",
    "### Training a random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88028eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets implement a RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "\n",
    "print(f\"Validation Accuracy -> {round(valid_auc_score,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bcf8ef",
   "metadata": {},
   "source": [
    "Every time we retrain the model, the score changes: it varies from 77% to 80%. <br>\n",
    "The reason for this is randomization: to train a tree, we randomly select a subset of features. <br>\n",
    "To make the results consistent, we need to fix the seed for the randomnumber generator by assigning some value to the random_state parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa66419",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=3)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "\n",
    "print(f\"Validation Accuracy -> {round(valid_auc_score,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cafce5",
   "metadata": {},
   "source": [
    "The number of trees in the ensemble is an important parameter, and it influences <br>\n",
    "the performance of the model. Usually, a model with more trees is better than a model <br>\n",
    "with fewer trees. On the other hand, adding too many trees is not always helpful. <br>\n",
    "To see how many trees we need, we can iterate over different values for n_estimators <br>\n",
    "and see its effect on AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "for i in range(10, 201, 10):\n",
    "    rf_model = RandomForestClassifier(n_estimators=i, random_state=3)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "    valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    print(f\"{i} - {round(valid_auc_score,2)}\")\n",
    "    \n",
    "    aucs.append(valid_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the results\n",
    "#plt.figure(figsize=(4, 6))\n",
    "plt.plot(range(10, 201, 10),aucs)\n",
    "\n",
    "\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Number of trees vs AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720889d",
   "metadata": {},
   "source": [
    "### Parameter tuning for random forest\n",
    "A random forest ensemble consists of multiple decision trees, so the most important\n",
    "parameters we need to tune for random forest are the same:\n",
    "- max_depth\n",
    "- min_leaf_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a dictionary with AUC results\n",
    "\n",
    "all_aucs = {}\n",
    "\n",
    "## iterates over different depth values\n",
    "for depth in [5, 10, 20]:\n",
    "    print(f\"depth: {depth}\")\n",
    "    aucs = []\n",
    "    \n",
    "    ## creates a list with auc results for the current depth level\n",
    "    for n in range(10, 201, 10):\n",
    "        ## iterates over different n_estimator values\n",
    "        rf_model = RandomForestClassifier(n_estimators=n, max_depth=depth, random_state=3)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        #lets evaluates the model\n",
    "        y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "        valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "        print(f\"{n} -> {round(valid_auc_score, 2)}\")\n",
    "        \n",
    "        aucs.append(valid_auc_score)\n",
    "    ##lets save all the aucs for the current depth level in the dictionary\n",
    "    all_aucs[depth] = aucs \n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ee6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = list(range(10, 201, 10))\n",
    "plt.plot(num_trees, all_aucs[5], label='depth=5')\n",
    "plt.plot(num_trees, all_aucs[10], label='depth=10')\n",
    "plt.plot(num_trees, all_aucs[20], label='depth=20')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a dictionary with AUC results\n",
    "\n",
    "all_aucs = {}\n",
    "\n",
    "## iterates over different depth values\n",
    "for leaf in [3, 5, 10]:\n",
    "    print(f\"min_samples_leaf: {leaf}\")\n",
    "    aucs = []\n",
    "    \n",
    "    ## creates a list with auc results for the current depth level\n",
    "    for n in range(10, 201, 10):\n",
    "        ## iterates over different n_estimator values\n",
    "        rf_model = RandomForestClassifier(n_estimators=n, max_depth=10, min_samples_leaf=leaf, random_state=3)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        #lets evaluates the model\n",
    "        y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "        valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "        print(f\"{n} -> {round(valid_auc_score, 3)}\")\n",
    "        \n",
    "        aucs.append(valid_auc_score)\n",
    "    ##lets save all the aucs for the current depth level in the dictionary\n",
    "    all_aucs[leaf] = aucs \n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = list(range(10, 201, 10))\n",
    "plt.plot(num_trees, all_aucs[3], label='min_samples_leaf=3')\n",
    "plt.plot(num_trees, all_aucs[5], label='min_samples_leaf=5')\n",
    "plt.plot(num_trees, all_aucs[10], label='min_samples_leaf=10')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3cfa5",
   "metadata": {},
   "source": [
    "###  Final Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3030f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=80, max_depth=10, min_samples_leaf=3, random_state=3)\n",
    "rf_model.fit(X_train, y_train)\n",
    "        \n",
    "#lets evaluates the model\n",
    "y_pred_valid = rf_model.predict_proba(X_valid)[:, 1]\n",
    "valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "print(f\"Validation Accuracy: -> {round(valid_auc_score, 3)}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceeaf25",
   "metadata": {},
   "source": [
    "## Gradient boosting \n",
    "Gradient boosting train models squentially, where each next model tries to fix errors from the previous one:\n",
    "- Train the first model\n",
    "- Look at the errors it makes \n",
    "- Train another model that fixes these errors\n",
    "- Look at the errors again, repeat sequentially. \n",
    "\n",
    "### XGBoost: Extreme gradient boosting \n",
    "Before we can train an XGBoost model, we need to wrap our data into DMatrix — a\n",
    "special data structure for finding splits efficiently.\n",
    "When creating an instance of DMatrix, we pass three parameters:\n",
    "- X_train: the feature matrix\n",
    "- y_train: the target variable\n",
    "- feature_names: the names of features in X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a566a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets implement xgboost\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77feb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets convert our training data into DMatrix form\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=dv.feature_names_)\n",
    "\n",
    "## lets convert our validation data into DMatrix form\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid, feature_names=dv.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db008362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets specify the parameters for training \n",
    "xgb_params = {\n",
    "    'eta':0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weigh': 1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8, \n",
    "    'seed': 1,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets start our training with 10 trees\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create our predictions\n",
    "y_pred_valid = xgb_model.predict(dvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets compute our accuracy\n",
    "valid_auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "print(f\"Validation Accuracy {round(valid_auc_score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ff264",
   "metadata": {},
   "source": [
    "### Model performance monitoring \n",
    "To get an idea of how AUC changes as the number of trees grows, we can use a watchlist\n",
    "— a built-in feature in XGBoost for monitoring model performance.\n",
    "A watchlist is a Python list with tuples. Each tuple contains a DMatrix and its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee17593",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a watch list\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a list of parameters for training \n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets train our model \n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a list of parameters for training \n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets train our model \n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=500, evals=watchlist, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3a2c2",
   "metadata": {},
   "source": [
    "#### OTHER PARAMETERS TUNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fe52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a list of parameters for training \n",
    "## lets tune the max_depth parameter\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92664559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets train our model \n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=500, evals=watchlist, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d6a28",
   "metadata": {},
   "source": [
    "### Testing the final model \n",
    "We’re almost ready to use it for risk scoring. We still need to do two things before we can use it:\n",
    "- Retrain the final model on both train and validation datasets combined. We no longer need the validation dataset, so we can use more data for training, which will make the model slightly better.\n",
    "- Test the model on the test set. This is the part of data we kept aside from the beginning. Now we use it to make sure the model didn’t overfit and performs well on completely unseen data. <br>\n",
    "\n",
    "The next steps are:\n",
    "\n",
    "- Apply the same preprocessing to df_full_train and df_test as we did to df_train and df_val. As a result, we get the feature matrices X_train and X_test as well as our target variables y_train and y_test.\n",
    "- Train a model on the combined dataset with the parameters we selected previously.\n",
    "- Apply the model to the test data to get the test predictions.\n",
    "- Verify that the model performs well and doesn’t overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create the target variable\n",
    "y_train = (df_train_full.status == 'default').values\n",
    "y_test = (df_test.status == 'default').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the target variable column from the dataframe\n",
    "del df_train_full['status']\n",
    "del df_test['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert the dataframe into a list of dictionaries\n",
    "## replace all missing values with zeros\n",
    "dict_train = df_train_full.fillna(0).to_dict(orient='records')\n",
    "dict_test = df_test.fillna(0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477529ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use one-hot encoding to get the feature matrices\n",
    "dict_vect = DictVectorizer(sparse=False)\n",
    "X_train = dict_vect.fit_transform(dict_train)\n",
    "X_test = dict_vect.fit_transform(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40406d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets train the XGBoost model using this data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=dict_vect.feature_names_)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=dict_vect.feature_names_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5679d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth':3,\n",
    "    'min_child_weigh':1,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_trees = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56298f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets evaluate the performance of the model\n",
    "y_pred_test = xgb_model.predict(dtest)\n",
    "\n",
    "## lets compute our accuracy\n",
    "valid_auc_score = roc_auc_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy {round(valid_auc_score, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007305ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
