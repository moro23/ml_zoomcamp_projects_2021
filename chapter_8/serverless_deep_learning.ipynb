{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aad42",
   "metadata": {},
   "source": [
    "## Serverless: AWS Lambda \n",
    "We want to build a web service that\n",
    "- Gets the URL in the request\n",
    "- Loads the image from this URL\n",
    "- Uses TensorFlow Lite to apply the model to the image and get the predictions\n",
    "- Responds with the results (figure 8.1)\n",
    "\n",
    "To create this service, we will need to\n",
    "\n",
    "- Convert the model from Keras to the TensorFlow Lite format\n",
    "- Preprocess the images â€” resize them and apply the preprocessing function\n",
    "- Package the code in a Docker image, and upload it to ECR (the Docker registry from AWS)\n",
    "- Create and test the lambda function on AWS\n",
    "- Make the lambda function available to everyone with AWS API Gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15547fd8",
   "metadata": {},
   "source": [
    "## Converting the model to TF Lite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bb5ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-01 09:11:51.919068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-01 09:11:51.919116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-01 09:11:54.588394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-01 09:11:54.588439: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-01 09:11:54.588469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-09-01 09:11:54.588705: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-01 09:12:08.114367: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-09-01 09:12:41.280218: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2022-09-01 09:12:41.280264: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2022-09-01 09:12:41.282635: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpfw6wiy5_\n",
      "2022-09-01 09:12:41.405224: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-09-01 09:12:41.405284: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/tmpfw6wiy5_\n",
      "2022-09-01 09:12:41.709532: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2022-09-01 09:12:43.422735: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: /tmp/tmpfw6wiy5_\n",
      "2022-09-01 09:12:43.831280: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 2548654 microseconds.\n",
      "2022-09-01 09:12:44.610336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "## lets turn the model to TF Lite format\n",
    "!python convert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323e964",
   "metadata": {},
   "source": [
    "## Preparing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7e69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "## lets load the Xception model with a target size\n",
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51104b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets get an image and prepare it\n",
    "image_url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7f99b",
   "metadata": {},
   "source": [
    "## Using the TensorFlow Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08f5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "## lets load the tflite model\n",
    "\n",
    "## create the tf lite interpreter\n",
    "interpreter = tflite.Interpreter('clothing-model-v4.tflite')\n",
    "\n",
    "## initializes the interpreter with the model\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "##\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "## \n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "\n",
    "##\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "##\n",
    "preds = interpreter.get_tensor(output_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f75cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "'dress',\n",
    "'hat',\n",
    "'longsleeve',\n",
    "'outwear',\n",
    "'pants',\n",
    "'shirt',\n",
    "'shoes',\n",
    "'shorts',\n",
    "'skirt',\n",
    "'t-shirt'\n",
    "]\n",
    "\n",
    "results = dict(zip(labels, preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3022eeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.5640455,\n",
       " 'hat': -4.702159,\n",
       " 'longsleeve': -0.96891385,\n",
       " 'outwear': -1.591752,\n",
       " 'pants': 9.307265,\n",
       " 'shirt': -1.4798162,\n",
       " 'shoes': -2.7068253,\n",
       " 'shorts': 3.1710477,\n",
       " 'skirt': -2.3949814,\n",
       " 't-shirt': -3.6138039}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f3199",
   "metadata": {},
   "source": [
    "## Code for the lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96180f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fb7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c3505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a5406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757f768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
